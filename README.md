# Real-Time Object Detection and Multi-Object Tracking in Dynamic Environments
This project presents a real-time object detection and multi-object tracking system designed for dynamic environments using the YOLO (You Only Look Once) deep learning framework. The study focuses on detecting and tracking multiple objects efficiently in video streams with high speed and accuracy, making it suitable for real-world applications such as surveillance, traffic monitoring, sports analytics, autonomous driving, and smart cities.
The system uses YOLOv5 for fast and accurate object detection and integrates Deep SORT for robust object tracking across video frames. The workflow includes data collection, preprocessing, model training, performance evaluation, and real-time tracking implementation. Experimental results demonstrate that the YOLO-based approach outperforms traditional region-based methods (such as R-CNN) in terms of inference speed, while maintaining strong precision, recall, and tracking stability.
The project also explores key challenges such as occlusion, motion blur, lighting variations, scale differences, and computational constraints, and discusses advanced enhancements including attention mechanisms, multi-scale feature fusion, optical flow integration, model optimization for edge devices, and reinforcement learning-based adaptive tracking.
Overall, this work highlights the effectiveness of YOLO-based models for real-time object detection and tracking and provides insights into future improvements for deployment on resource-constrained and embedded systems.
